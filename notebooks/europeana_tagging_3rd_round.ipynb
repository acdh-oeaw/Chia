{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score as cks\n",
    "from tabulate import tabulate\n",
    "\n",
    "import imgkit\n",
    "from IPython.display import display\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "#InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "pd.set_option('precision', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the dataframe with the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading original files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '../data/img_labeling_3rd_round/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 .csv files in the folder\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_files = sorted(os.listdir(datapath))\n",
    "label_files = [f for f in label_files if 'csv' in f and \"_\" in f]\n",
    "print(f\"{len(label_files)} .csv files in the folder\\n\")\n",
    "#for f in label_files:\n",
    "#    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 diferent subjects\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subjects = {x[:x.find(\"_\")] for x in label_files}\n",
    "print(f\"{len(subjects)} diferent subjects\\n\")\n",
    "#for s in sorted(subjects):\n",
    "#    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consolidating files per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_files = []\n",
    "for subject in subjects:\n",
    "    subject_files = [os.path.join(datapath, f) for f in label_files if f.startswith(subject)]\n",
    "    consolidated_file = os.path.join(datapath, subject + \".csv\")\n",
    "    consolidated_files.append(consolidated_file)\n",
    "    with open(consolidated_file, \"w\") as fw:\n",
    "        for s in subject_files:\n",
    "            with open(s, \"r\") as fr:\n",
    "                lines = fr.read()\n",
    "                lines = lines.replace('\"','')\n",
    "                lines = lines.replace(\"[Appealing,Non-appealing]\", \"[Non-appealing]\")   ## Choosing the last chosen class for ambiguous\n",
    "                lines = lines.replace(\"[Non-appealing,Appealing]\", \"[Appealing]\")\n",
    "                fw.write(lines+\"\\n\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading CSV files into Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:1, hash: \t 245DC3767EBDBF721824F2F09B4251D5E0063494 tagged 1012 images\n",
      "User:2, hash: \t F9CC3D73B8F36057257097AFFE29B884000BABB5 tagged 1011 images\n",
      "User:3, hash: \t 867D8B4F797167AA1CA27E00F76B51C63A7278ED tagged 499 images\n",
      "User:4, hash: \t A6241D7982404859C8D816D8C4A61DC506145A50 tagged 1011 images\n",
      "User:5, hash: \t C003DF0C2EC67886EA6BC835682E3182A2126135 tagged 1009 images\n",
      "User:6, hash: \t C6C77B9A8025D969F0E14BEBBEECB8B82BAAF284 tagged 1011 images\n",
      "User:7, hash: \t 43166EAC7DE5C6D48FF646B1B12BEB46AC7CA375 tagged 1008 images\n",
      "User:8, hash: \t B59DE8F9A0D4C9AADABAFF7EA6A4F61BF89861DA tagged 1012 images\n",
      "User:9, hash: \t BE887E16DEB41D06FACD481B5BFE3AF6FDF6F8CB tagged 1012 images\n",
      "User:10, hash: \t 38205FF03AFF19E008FA123615336213A0ED33AB tagged 1010 images\n",
      "User:11, hash: \t 3AB6D9AAC2244ECC4F595743DF6EB54686DE31A0 tagged 1012 images\n",
      "User:12, hash: \t C733B58CB8AE244885A97E86B09D896A5633674C tagged 1010 images\n",
      "User:13, hash: \t C91C4E40D11000EB5E5BE0EDBE12C74A54FAA40B tagged 500 images\n",
      "User:14, hash: \t 73396439E5B11BBCA57A8FCB53FBB6F0FCECE794 tagged 1007 images\n",
      "User:15, hash: \t 8D396D662D61B164860C081535E30C3E32934406 tagged 1012 images\n",
      "User:16, hash: \t F96F6ACF9B40EDA60D4D48FBED7B3512E1C8E48D tagged 1012 images\n",
      "User:17, hash: \t 6438BC09053F6B5215CA1FC743AB0E3CF2B53984 tagged 1012 images\n",
      "User:18, hash: \t F0E0055FB33661B91E7C55DAFB0246BCB43D7D8D tagged 495 images\n",
      "User:19, hash: \t 5FFB96918AA02D6E1EF82257A2828F9A4FD9C702 tagged 1101 images\n",
      "User:20, hash: \t 5FEF4C8B719CABDF32C46A4C9C9316376DF7B512 tagged 500 images\n"
     ]
    }
   ],
   "source": [
    "list_dfs = []\n",
    "for idx, consolidated_file in enumerate(consolidated_files):\n",
    "    user = re.findall(\"|\".join(subjects), consolidated_file)[0]\n",
    "    userid = idx + 1\n",
    "    df = pd.read_csv(consolidated_file, names=['image_name', 'class','w','h'])\n",
    "    print(f\"User:{userid}, hash: \\t {user} tagged {len(df)} images\")\n",
    "    df['user'] = user\n",
    "    df['userid'] = userid\n",
    "    df.drop(['w','h'], axis=1, inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    list_dfs.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18156 entries, 0 to 499\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   userid      18156 non-null  int64 \n",
      " 1   user        18156 non-null  object\n",
      " 2   image_name  18156 non-null  object\n",
      " 3   id_image    18156 non-null  object\n",
      " 4   class       18156 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 851.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_labeling = pd.concat(list_dfs)\n",
    "df_labeling['id_image'] = df_labeling['image_name'].apply(lambda x:x[:-4])\n",
    "df_labeling = df_labeling[['userid','user', 'image_name', 'id_image', 'class']]\n",
    "df_labeling.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixing classes names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[Non-appealing]' '[Appealing]' '[Appealing]    ' '[Npn-appealing]']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Non-appealing    11076\n",
       "Appealing         7080\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_labeling['class'].unique())\n",
    "df_labeling[\"class\"] = df_labeling[\"class\"].str.strip(\"[] \")\n",
    "df_labeling[\"class\"].replace({'Npn-appealing':\"Non-appealing\"}, inplace=True)\n",
    "df_labeling['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>user</th>\n",
       "      <th>image_name</th>\n",
       "      <th>id_image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>245DC3767EBDBF721824F2F09B4251D5E0063494</td>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Non-appealing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>245DC3767EBDBF721824F2F09B4251D5E0063494</td>\n",
       "      <td>2.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>Appealing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>245DC3767EBDBF721824F2F09B4251D5E0063494</td>\n",
       "      <td>3.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>Non-appealing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>245DC3767EBDBF721824F2F09B4251D5E0063494</td>\n",
       "      <td>4.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Non-appealing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>245DC3767EBDBF721824F2F09B4251D5E0063494</td>\n",
       "      <td>5.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>Non-appealing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid                                      user image_name id_image  \\\n",
       "0       1  245DC3767EBDBF721824F2F09B4251D5E0063494      1.jpg        1   \n",
       "1       1  245DC3767EBDBF721824F2F09B4251D5E0063494      2.jpg        2   \n",
       "2       1  245DC3767EBDBF721824F2F09B4251D5E0063494      3.jpg        3   \n",
       "3       1  245DC3767EBDBF721824F2F09B4251D5E0063494      4.jpg        4   \n",
       "4       1  245DC3767EBDBF721824F2F09B4251D5E0063494      5.jpg        5   \n",
       "\n",
       "           class  \n",
       "0  Non-appealing  \n",
       "1      Appealing  \n",
       "2  Non-appealing  \n",
       "3  Non-appealing  \n",
       "4  Non-appealing  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeling.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding users' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/img_labeling_3rd_round/ChIA-CulturalQuestionnaire-results-raw data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f2c316276380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m profiles = pd.read_csv(os.path.join(datapath, 'ChIA-CulturalQuestionnaire-results-raw data.csv'), \n\u001b[0m\u001b[1;32m      2\u001b[0m                        names=[\"timestamp\", \"age\", \"gender\", \"country\", \"discard1\", \"culturalBack\", \"culture\", \"hash\", \"discard2\"])\n\u001b[1;32m      3\u001b[0m \u001b[0mprofiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"discard1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"discard2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprofiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/default_env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/default_env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/default_env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/default_env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1043\u001b[0m             )\n\u001b[1;32m   1044\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/default_env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1863\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/default_env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \"\"\"\n\u001b[0;32m-> 1357\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1358\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/default_env/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/img_labeling_3rd_round/ChIA-CulturalQuestionnaire-results-raw data.csv'"
     ]
    }
   ],
   "source": [
    "profiles = pd.read_csv(os.path.join(datapath, 'ChIA-CulturalQuestionnaire-results-raw data.csv'), \n",
    "                       names=[\"timestamp\", \"age\", \"gender\", \"country\", \"discard1\", \"culturalBack\", \"culture\", \"hash\", \"discard2\"])\n",
    "profiles.drop([\"timestamp\", \"discard1\", \"discard2\"], axis=1, inplace=True)\n",
    "profiles.drop([0,1], axis=0, inplace=True)\n",
    "\n",
    "profiles[\"age\"] = profiles.age.str.replace(\"-\",\",\").str.strip(\"+\")\n",
    "profiles[\"age\"] = profiles.age.apply(lambda x:eval(f\"[{x}]\"))\n",
    "profiles[\"age\"] = [np.mean(np.array(x)).astype(int) for x in profiles.age]\n",
    "\n",
    "profiles.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_labeling.join(profiles.set_index('hash'), on='user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Users with no profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.gender.isnull()].user.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Users with profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.gender.notnull()].user.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking images classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeling['image_appearances'] = df_labeling.groupby('id_image')['id_image'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(df_labeling['image_name'])} images were classified\")\n",
    "print(f\"{len(df_labeling['image_name'].unique())} unique images were classified\\n\")\n",
    "num_images = 0\n",
    "image_appearances = df_labeling.image_appearances.value_counts().sort_index(ascending=True)\n",
    "for idx in image_appearances.index:\n",
    "    print(f'{image_appearances[idx]} images were classified {idx} times')\n",
    "    num_images += image_appearances[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keeping the images that were classified by all subjects (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_labeling = df_labeling[df_labeling['image_appearances'] == 20]\n",
    "df_labeling.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing the [inter-annotator agreement](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.cohen_kappa_score.html) on the results  \n",
    "\n",
    "### $\\kappa = (p_o - p_e) / (1 - p_e)$\n",
    "\n",
    "#### where $p_o$ is the empirical probability of agreement on the label assigned to any sample (the observed agreement ratio), and $p_e$ is the expected agreement when both annotators assign labels randomly. $p_e$ is estimated using a per-annotator empirical prior over the class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = df_labeling.userid.unique()\n",
    "iter_users = itertools.product(l1,l1)\n",
    "df_iaa = pd.DataFrame(index=l1, columns=l1)\n",
    "df_iaa_styled = pd.DataFrame(index=l1, columns=l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_agreement = 0\n",
    "for user1,user2 in iter_users:\n",
    "    classesA = df_labeling.loc[(df_labeling.userid == user1),['id_image', 'class']]\n",
    "    classesA.sort_values(by=['id_image'], inplace=True)\n",
    "\n",
    "    classesB = df_labeling.loc[(df_labeling.userid == user2),['id_image', 'class']]\n",
    "    classesB.sort_values(by=['id_image'], inplace=True)\n",
    "\n",
    "    classesAB = pd.merge(classesA, classesB, on=['id_image'])\n",
    "    #classesAB.drop_duplicates(subset='id_image', keep = 'first', inplace=True) \n",
    "    classesAB.drop('id_image', axis=1, inplace=True)\n",
    "    classesAB.dropna(inplace=True)\n",
    "\n",
    "    agreement = cks(classesAB['class_x'], classesAB['class_y'])\n",
    "    total_agreement += agreement\n",
    "    df_iaa.loc[user1,user2] = f'{agreement:.3f}/({len(classesAB)})'\n",
    "    df_iaa_styled.loc[user1,user2] = f'{agreement:.3f}'\n",
    "    \n",
    "df_iaa_styled = df_iaa_styled.apply(pd.to_numeric)\n",
    "print(tabulate(df_iaa, headers='keys', tablefmt='psql'))\n",
    "print(f'\\nThe average agreement was {total_agreement/(len(l1)**2):.3f}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "cm = 'viridis'\n",
    "cm = 'plasma'\n",
    "#cm = 'magma'\n",
    "\n",
    "s = df_iaa_styled.style.background_gradient(cmap=cm, vmin=0, vmax=1, axis=None)\n",
    "display(s)\n",
    "html = s.render()\n",
    "imgkit.from_string(html, f'../data/outputs/styled_table_round3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iaa.to_excel(\"../data/outputs/round3_results.xls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis per gender and country/culture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeling.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeling['round'] = 3\n",
    "df_labeling.drop('image_appearances', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_labeling.to_hdf('../data/df_labeling.hdf', key='round3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
